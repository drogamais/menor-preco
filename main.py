# main.py
import os
import logging
from datetime import datetime, timezone, timedelta
import pandas as pd

# Importa as configs
from config import DB_CONFIG, GOOGLE_API_KEY, TELEGRAM_TOKEN, TELEGRAM_CHAT_ID

# Importa os m√≥dulos de execu√ß√£o
from MP_Feeder.flow import run_recovery_flow, run_normal_flow
from MP_Feeder.error_handler import handle_execution_error, handle_api_fail, handle_success
from MP_Feeder.etl_utils import setup_logging
from MP_Feeder.db_manager import inserir_lojas_sc, inserir_notas
from MP_Feeder.api_services import buscar_lat_lon_lojas_sc

def main():
    # --- CONFIGURA√á√ïES DE EXECU√á√ÉO ---
    gmt_menos_3 = timezone(timedelta(hours=-3))
    now_gmt3 = datetime.now(gmt_menos_3)
    today_gmt3 = now_gmt3.date()
    
    # Agrupa todas as configs
    configs = {
        "DB_CONFIG": DB_CONFIG,
        "GOOGLE_API_KEY": GOOGLE_API_KEY,
        "TELEGRAM_TOKEN": TELEGRAM_TOKEN,
        "TELEGRAM_CHAT_ID": TELEGRAM_CHAT_ID,
        "arquivo_indice": "ultimo_indice.txt",
        "arquivo_notas_parciais": "notas_parciais.csv",
        "arquivo_lojas_parciais": "lojas_parciais.csv"
    }
    
    # --- LOOP PRINCIPAL DE EXECU√á√ÉO ---
    while True:
        Notas_geral = pd.DataFrame()
        Lojas_SC_geral = pd.DataFrame()
        run_completo = False
        indice_para_salvar = 0

        try:
            # --- PASSO 1: VERIFICAR/EXECUTAR RECUPERA√á√ÉO DE CSV ---
            if os.path.exists(configs['arquivo_notas_parciais']):
                run_recovery_flow(configs, now_gmt3)
                print("##### RECUPERA√á√ÉO CONCLU√çDA. CONTINUANDO PARA A COLETA DA API... #####")
                print("\n" + "="*50 + "\n")
                continue 
            
            # --- PASSO 2: EXECUTAR FLUXO NORMAL (S√ì EXTRA√á√ÉO/TRANSFORMA√á√ÉO) ---
            else:
                # O flow agora S√ì coleta e transforma, e RETORNA os dados
                Notas_geral, Lojas_SC_geral, run_completo, indice_para_salvar = run_normal_flow(
                    configs, now_gmt3, today_gmt3
                )
            
            # --- PASSO 3: CARGA (LOAD) ---
            
            ### VIII Carga de Novas Lojas
            if not Lojas_SC_geral.empty:
                Lojas_SC_geral_sem_duplicatas = Lojas_SC_geral.drop_duplicates(subset=["id_loja"]).reset_index(drop=True)
                print(f"##### üíæ SALVANDO {len(Lojas_SC_geral_sem_duplicatas)} LOJAS (TOTAIS OU PARCIAIS)... #####")
                Lojas_SC_com_latlon = buscar_lat_lon_lojas_sc(Lojas_SC_geral_sem_duplicatas, GOOGLE_API_KEY)
                inserir_lojas_sc(Lojas_SC_com_latlon, now_gmt3, DB_CONFIG)
            else:
                print("##### NENHUMA LOJA NOVA ENCONTRADA PARA CARGA. #####")

            ### IX Carga das Notas Fiscais:
            if not Notas_geral.empty:
                Notas_geral_sem_duplicatas = Notas_geral.drop_duplicates(subset=["id_nota"]).reset_index(drop=True)
                print(f"##### üíæ SALVANDO {len(Notas_geral_sem_duplicatas)} NOTAS (TOTAIS OU PARCIAIS)... #####")
                inserir_notas(Notas_geral_sem_duplicatas, now_gmt3, DB_CONFIG)
            else:
                print("##### NENHUMA NOTA NOVA ENCONTRADA PARA CARGA. #####")

            # --- PASSO 4: LIDAR COM O RESULTADO ---
            if run_completo:
                handle_success(
                    configs['arquivo_indice'], now_gmt3, 
                    TELEGRAM_TOKEN, TELEGRAM_CHAT_ID
                )
                break 
            else:
                handle_api_fail(indice_para_salvar)

        except Exception as e:
            # --- PASSO 5: LIDAR COM FALHA CATASTR√ìFICA ---

            handle_execution_error(
                e, Notas_geral, Lojas_SC_geral, indice_para_salvar,
                now_gmt3, TELEGRAM_TOKEN, TELEGRAM_CHAT_ID
            )

if __name__ == "__main__":
    setup_logging()
    main()